{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Model Training and Experimentation\n",
        "\n",
        "This notebook demonstrates interactive model training and hyperparameter experimentation for the text classification pipeline.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "ename": "",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31mRunning cells with 'ML_NLP (Python 3.12.7)' requires the ipykernel package.\n",
            "\u001b[1;31mInstall 'ipykernel' into the Python environment. \n",
            "\u001b[1;31mCommand: 'd:/Mishthi/chakaralya_analytics_ML_NLP/ML_NLP/Scripts/python.exe -m pip install ipykernel -U --force-reinstall'"
          ]
        }
      ],
      "source": [
        "\n",
        "import os\n",
        "import sys\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from tqdm.auto import tqdm\n",
        "\n",
        "# Hugging Face Ecosystem\n",
        "from datasets import load_dataset, Dataset, DatasetDict\n",
        "from transformers import (\n",
        "    AutoTokenizer, AutoModelForSequenceClassification,\n",
        "    TrainingArguments, Trainer, DataCollatorWithPadding,\n",
        "    pipeline, set_seed\n",
        ")\n",
        "import torch\n",
        "from torch.utils.data import DataLoader\n",
        "\n",
        "# Optimization and Evaluation\n",
        "import optuna\n",
        "from sklearn.metrics import accuracy_score, precision_recall_fscore_support, confusion_matrix, classification_report\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# Visualization\n",
        "plt.style.use('seaborn-v0_8')\n",
        "sns.set_palette(\"husl\")\n",
        "\n",
        "# Configuration\n",
        "CONFIG = {\n",
        "    'model_name': 'distilbert-base-uncased',\n",
        "    'multilingual_model': 'distilbert-base-multilingual-cased',\n",
        "    'max_length': 512,\n",
        "    'batch_size': 16,\n",
        "    'learning_rate': 2e-5,\n",
        "    'num_epochs': 3,\n",
        "    'seed': 42,\n",
        "    'device': 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "}\n",
        "\n",
        "set_seed(CONFIG['seed'])\n",
        "print(f\"üöÄ Training Environment: {CONFIG['device']}\")\n",
        "print(f\"üìä Configuration: {CONFIG}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "\n",
        "class DatasetManager:\n",
        "    \"\"\"Comprehensive dataset management for text classification\"\"\"\n",
        "    \n",
        "    def __init__(self):\n",
        "        self.supported_datasets = {\n",
        "            'imdb': {'task': 'sentiment', 'labels': ['NEGATIVE', 'POSITIVE']},\n",
        "            'ag_news': {'task': 'topic', 'labels': ['World', 'Sports', 'Business', 'Technology']},\n",
        "            'yelp_review_full': {'task': 'sentiment', 'labels': ['1', '2', '3', '4', '5']},\n",
        "            'emotion': {'task': 'emotion', 'labels': ['sadness', 'joy', 'love', 'anger', 'fear', 'surprise']}\n",
        "        }\n",
        "    \n",
        "    def load_dataset(self, dataset_name, sample_size=None):\n",
        "        \"\"\"Load and sample dataset with comprehensive analysis\"\"\"\n",
        "        print(f\"üìÅ Loading {dataset_name} dataset...\")\n",
        "        \n",
        "        if dataset_name not in self.supported_datasets:\n",
        "            raise ValueError(f\"Dataset {dataset_name} not supported. Available: {list(self.supported_datasets.keys())}\")\n",
        "        \n",
        "        # Load dataset\n",
        "        if dataset_name == 'ag_news':\n",
        "            dataset = load_dataset('ag_news')\n",
        "        elif dataset_name == 'yelp_review_full':\n",
        "            dataset = load_dataset('yelp_review_full')\n",
        "        elif dataset_name == 'emotion':\n",
        "            dataset = load_dataset('emotion')\n",
        "        else:\n",
        "            dataset = load_dataset(dataset_name)\n",
        "        \n",
        "        # Sample for faster experimentation\n",
        "        if sample_size:\n",
        "            train_size = min(sample_size, len(dataset['train']))\n",
        "            test_size = min(sample_size // 4, len(dataset['test']))\n",
        "            \n",
        "            dataset['train'] = dataset['train'].shuffle(seed=42).select(range(train_size))\n",
        "            dataset['test'] = dataset['test'].shuffle(seed=42).select(range(test_size))\n",
        "        \n",
        "        # Dataset analysis\n",
        "        self.analyze_dataset(dataset, dataset_name)\n",
        "        return dataset\n",
        "    \n",
        "    def analyze_dataset(self, dataset, name):\n",
        "        \"\"\"Comprehensive dataset analysis with visualizations\"\"\"\n",
        "        train_data = dataset['train']\n",
        "        test_data = dataset['test']\n",
        "        \n",
        "        print(f\"\\nüìä Dataset Analysis: {name}\")\n",
        "        print(f\"Train samples: {len(train_data):,}\")\n",
        "        print(f\"Test samples: {len(test_data):,}\")\n",
        "        \n",
        "        # Label distribution\n",
        "        train_labels = train_data['label']\n",
        "        label_counts = pd.Series(train_labels).value_counts().sort_index()\n",
        "        \n",
        "        # Visualization\n",
        "        fig, axes = plt.subplots(2, 2, figsize=(15, 10))\n",
        "        \n",
        "        # Label distribution\n",
        "        axes[0,0].bar(range(len(label_counts)), label_counts.values)\n",
        "        axes[0,0].set_title('Training Label Distribution')\n",
        "        axes[0,0].set_xlabel('Label')\n",
        "        axes[0,0].set_ylabel('Count')\n",
        "        \n",
        "        # Text length distribution\n",
        "        text_lengths = [len(text.split()) for text in train_data['text']]\n",
        "        axes[0,1].hist(text_lengths, bins=50, alpha=0.7)\n",
        "        axes[0,1].set_title('Text Length Distribution')\n",
        "        axes[0,1].set_xlabel('Number of Words')\n",
        "        axes[0,1].set_ylabel('Frequency')\n",
        "        \n",
        "        # Character length distribution\n",
        "        char_lengths = [len(text) for text in train_data['text']]\n",
        "        axes[1,0].hist(char_lengths, bins=50, alpha=0.7, color='orange')\n",
        "        axes[1,0].set_title('Character Length Distribution')\n",
        "        axes[1,0].set_xlabel('Number of Characters')\n",
        "        axes[1,0].set_ylabel('Frequency')\n",
        "        \n",
        "        # Sample texts per label\n",
        "        axes[1,1].axis('off')\n",
        "        sample_text = \"Sample texts:\\n\\n\"\n",
        "        for i, label in enumerate(set(train_labels[:100])):\n",
        "            sample_idx = next(idx for idx, lbl in enumerate(train_labels) if lbl == label)\n",
        "            sample_text += f\"Label {label}: {train_data['text'][sample_idx][:100]}...\\n\\n\"\n",
        "        axes[1,1].text(0.1, 0.9, sample_text, transform=axes[1,1].transAxes, \n",
        "                      verticalalignment='top', fontsize=8)\n",
        "        \n",
        "        plt.tight_layout()\n",
        "        plt.show()\n",
        "        \n",
        "        print(f\"üìà Statistics:\")\n",
        "        print(f\"Average text length: {np.mean(text_lengths):.1f} words\")\n",
        "        print(f\"Max text length: {max(text_lengths)} words\")\n",
        "        print(f\"Average character length: {np.mean(char_lengths):.1f} characters\")\n",
        "\n",
        "# Initialize and load dataset\n",
        "dataset_manager = DatasetManager()\n",
        "dataset = dataset_manager.load_dataset('imdb', sample_size=5000)  # Adjust size as needed\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "\n",
        "class AdvancedTrainer:\n",
        "    \"\"\"Advanced training framework with hyperparameter optimization\"\"\"\n",
        "    \n",
        "    def __init__(self, dataset, config):\n",
        "        self.dataset = dataset\n",
        "        self.config = config\n",
        "        self.tokenizer = None\n",
        "        self.model = None\n",
        "        self.trainer = None\n",
        "        self.study = None\n",
        "        \n",
        "    def setup_tokenizer_and_model(self, model_name=None, num_labels=2):\n",
        "        \"\"\"Initialize tokenizer and model\"\"\"\n",
        "        model_name = model_name or self.config['model_name']\n",
        "        \n",
        "        print(f\"üîß Setting up {model_name}...\")\n",
        "        self.tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
        "        self.model = AutoModelForSequenceClassification.from_pretrained(\n",
        "            model_name, \n",
        "            num_labels=num_labels\n",
        "        )\n",
        "        \n",
        "        # Add padding token if not present\n",
        "        if self.tokenizer.pad_token is None:\n",
        "            self.tokenizer.pad_token = self.tokenizer.eos_token\n",
        "    \n",
        "    def preprocess_data(self):\n",
        "        \"\"\"Advanced data preprocessing with tokenization\"\"\"\n",
        "        def tokenize_function(examples):\n",
        "            return self.tokenizer(\n",
        "                examples['text'],\n",
        "                truncation=True,\n",
        "                padding=True,\n",
        "                max_length=self.config['max_length']\n",
        "            )\n",
        "        \n",
        "        print(\"üîÑ Preprocessing data...\")\n",
        "        tokenized_dataset = self.dataset.map(tokenize_function, batched=True)\n",
        "        \n",
        "        # Create validation split if not present\n",
        "        if 'validation' not in tokenized_dataset:\n",
        "            train_test = tokenized_dataset['train'].train_test_split(test_size=0.2, seed=42)\n",
        "            tokenized_dataset = DatasetDict({\n",
        "                'train': train_test['train'],\n",
        "                'validation': train_test['test'],\n",
        "                'test': tokenized_dataset['test']\n",
        "            })\n",
        "        \n",
        "        return tokenized_dataset\n",
        "    \n",
        "    def compute_metrics(self, eval_pred):\n",
        "        \"\"\"Comprehensive metrics computation\"\"\"\n",
        "        predictions, labels = eval_pred\n",
        "        predictions = np.argmax(predictions, axis=1)\n",
        "        \n",
        "        precision, recall, f1, _ = precision_recall_fscore_support(\n",
        "            labels, predictions, average='weighted'\n",
        "        )\n",
        "        accuracy = accuracy_score(labels, predictions)\n",
        "        \n",
        "        return {\n",
        "            'accuracy': accuracy,\n",
        "            'f1': f1,\n",
        "            'precision': precision,\n",
        "            'recall': recall\n",
        "        }\n",
        "    \n",
        "    def create_trainer(self, tokenized_dataset, trial_params=None):\n",
        "        \"\"\"Create trainer with custom configuration\"\"\"\n",
        "        params = trial_params or {\n",
        "            'learning_rate': self.config['learning_rate'],\n",
        "            'per_device_train_batch_size': self.config['batch_size'],\n",
        "            'num_train_epochs': self.config['num_epochs']\n",
        "        }\n",
        "        \n",
        "        training_args = TrainingArguments(\n",
        "            output_dir='./results',\n",
        "            evaluation_strategy='epoch',\n",
        "            save_strategy='epoch',\n",
        "            logging_dir='./logs',\n",
        "            load_best_model_at_end=True,\n",
        "            metric_for_best_model='f1',\n",
        "            greater_is_better=True,\n",
        "            save_total_limit=2,\n",
        "            report_to=None,\n",
        "            **params\n",
        "        )\n",
        "        \n",
        "        self.trainer = Trainer(\n",
        "            model=self.model,\n",
        "            args=training_args,\n",
        "            train_dataset=tokenized_dataset['train'],\n",
        "            eval_dataset=tokenized_dataset['validation'],\n",
        "            tokenizer=self.tokenizer,\n",
        "            data_collator=DataCollatorWithPadding(tokenizer=self.tokenizer),\n",
        "            compute_metrics=self.compute_metrics\n",
        "        )\n",
        "        \n",
        "        return self.trainer\n",
        "    \n",
        "    def hyperparameter_optimization(self, tokenized_dataset, n_trials=20):\n",
        "        \"\"\"Advanced hyperparameter optimization with Optuna\"\"\"\n",
        "        print(f\"üéØ Starting hyperparameter optimization with {n_trials} trials...\")\n",
        "        \n",
        "        def objective(trial):\n",
        "            # Define search space\n",
        "            params = {\n",
        "                'learning_rate': trial.suggest_float('learning_rate', 1e-6, 1e-4, log=True),\n",
        "                'per_device_train_batch_size': trial.suggest_categorical('batch_size', [16, 32]),\n",
        "                'num_train_epochs': trial.suggest_int('num_train_epochs', 2, 5),\n",
        "                'weight_decay': trial.suggest_float('weight_decay', 0.0, 0.3),\n",
        "                'warmup_ratio': trial.suggest_float('warmup_ratio', 0.0, 0.2)\n",
        "            }\n",
        "            \n",
        "            # Reinitialize model for each trial\n",
        "            self.setup_tokenizer_and_model(num_labels=len(set(self.dataset['train']['label'])))\n",
        "            \n",
        "            # Create trainer with trial parameters\n",
        "            trainer = self.create_trainer(tokenized_dataset, params)\n",
        "            \n",
        "            # Train and evaluate\n",
        "            trainer.train()\n",
        "            eval_results = trainer.evaluate()\n",
        "            \n",
        "            return eval_results['eval_f1']\n",
        "        \n",
        "        # Create and run study\n",
        "        self.study = optuna.create_study(direction='maximize')\n",
        "        self.study.optimize(objective, n_trials=n_trials)\n",
        "        \n",
        "        print(f\"üèÜ Best trial: {self.study.best_trial.value:.4f}\")\n",
        "        print(f\"üìä Best parameters: {self.study.best_trial.params}\")\n",
        "        \n",
        "        return self.study.best_trial.params\n",
        "    \n",
        "    def train_model(self, tokenized_dataset, use_best_params=False):\n",
        "        \"\"\"Train model with optional best parameters\"\"\"\n",
        "        if use_best_params and self.study:\n",
        "            print(\"üöÄ Training with optimized hyperparameters...\")\n",
        "            trainer = self.create_trainer(tokenized_dataset, self.study.best_trial.params)\n",
        "        else:\n",
        "            print(\"üöÄ Training with default parameters...\")\n",
        "            trainer = self.create_trainer(tokenized_dataset)\n",
        "        \n",
        "        # Train the model\n",
        "        train_result = trainer.train()\n",
        "        \n",
        "        # Save model and tokenizer\n",
        "        trainer.save_model('./models/trained_model')\n",
        "        self.tokenizer.save_pretrained('./models/tokenizer')\n",
        "        \n",
        "        print(\"‚úÖ Training completed!\")\n",
        "        print(f\"üìä Training metrics: {train_result.metrics}\")\n",
        "        \n",
        "        return trainer\n",
        "\n",
        "# Initialize advanced trainer\n",
        "advanced_trainer = AdvancedTrainer(dataset, CONFIG)\n",
        "\n",
        "# Setup model for IMDB (binary classification)\n",
        "num_labels = len(set(dataset['train']['label']))\n",
        "advanced_trainer.setup_tokenizer_and_model(num_labels=num_labels)\n",
        "\n",
        "# Preprocess data\n",
        "tokenized_dataset = advanced_trainer.preprocess_data()\n",
        "print(f\"‚úÖ Data preprocessing completed!\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "\n",
        "def interactive_training_session():\n",
        "    \"\"\"Interactive training session with multiple options\"\"\"\n",
        "    print(\"üöÄ Interactive Training Session\")\n",
        "    print(\"=\" * 50)\n",
        "    \n",
        "    options = {\n",
        "        '1': 'Quick Training (Default Parameters)',\n",
        "        '2': 'Hyperparameter Optimization',\n",
        "        '3': 'Model Comparison',\n",
        "        '4': 'Multilingual Training',\n",
        "        '5': 'Custom Configuration'\n",
        "    }\n",
        "    \n",
        "    for key, value in options.items():\n",
        "        print(f\"{key}. {value}\")\n",
        "    \n",
        "    choice = input(\"\\nSelect training option (1-5): \").strip()\n",
        "    \n",
        "    if choice == '1':\n",
        "        # Quick training\n",
        "        print(\"\\nüöÄ Starting quick training...\")\n",
        "        trainer = advanced_trainer.train_model(tokenized_dataset)\n",
        "        return trainer\n",
        "        \n",
        "    elif choice == '2':\n",
        "        # Hyperparameter optimization\n",
        "        n_trials = int(input(\"Number of optimization trials (default 10): \") or \"10\")\n",
        "        best_params = advanced_trainer.hyperparameter_optimization(tokenized_dataset, n_trials)\n",
        "        \n",
        "        # Train with best parameters\n",
        "        trainer = advanced_trainer.train_model(tokenized_dataset, use_best_params=True)\n",
        "        return trainer\n",
        "        \n",
        "    elif choice == '3':\n",
        "        # Model comparison\n",
        "        return model_comparison_experiment(tokenized_dataset)\n",
        "        \n",
        "    elif choice == '4':\n",
        "        # Multilingual training\n",
        "        return multilingual_training_experiment()\n",
        "        \n",
        "    elif choice == '5':\n",
        "        # Custom configuration\n",
        "        return custom_training_configuration(tokenized_dataset)\n",
        "    \n",
        "    else:\n",
        "        print(\"‚ùå Invalid choice. Using default training...\")\n",
        "        return advanced_trainer.train_model(tokenized_dataset)\n",
        "\n",
        "def model_comparison_experiment(tokenized_dataset):\n",
        "    \"\"\"Compare multiple model architectures\"\"\"\n",
        "    models_to_compare = [\n",
        "        'distilbert-base-uncased',\n",
        "        'bert-base-uncased',\n",
        "        'roberta-base'\n",
        "    ]\n",
        "    \n",
        "    results = {}\n",
        "    \n",
        "    for model_name in models_to_compare:\n",
        "        print(f\"\\nüîÑ Training {model_name}...\")\n",
        "        \n",
        "        # Setup model\n",
        "        advanced_trainer.setup_tokenizer_and_model(model_name, num_labels)\n",
        "        \n",
        "        # Train\n",
        "        trainer = advanced_trainer.train_model(tokenized_dataset)\n",
        "        \n",
        "        # Evaluate\n",
        "        eval_results = trainer.evaluate()\n",
        "        results[model_name] = eval_results\n",
        "        \n",
        "        print(f\"‚úÖ {model_name} - F1: {eval_results['eval_f1']:.4f}\")\n",
        "    \n",
        "    # Display comparison\n",
        "    comparison_df = pd.DataFrame(results).T\n",
        "    print(\"\\nüìä Model Comparison Results:\")\n",
        "    print(comparison_df[['eval_accuracy', 'eval_f1', 'eval_precision', 'eval_recall']])\n",
        "    \n",
        "    return results\n",
        "\n",
        "# Run interactive training\n",
        "print(\"Starting Interactive Training Session...\")\n",
        "training_results = interactive_training_session()\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "ML_NLP",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.12.7"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 4
}
